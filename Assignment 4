import matplotlib.pyplot as plt
import numpy as np

#start by defining the three functions as follows:
def f1(x): #x^2
    return x**2 

def f2(x): #x^4 - 2x^2
    return (x**4)-(2*(x**2))
    
def f3(x): #abs(x^x)
    if x>0:
        return x**x
    elif x==0:
        return 1
    else:
        return abs(x)**abs(x)
        
def deriv(f, initial_point):
    return (f(initial_point+10**(-5))-f(initial_point))/(10**(-5)) #intuitively, taking some low x > 0 to check for the IROC at this point (lol)
    
def gradient_descent(f, learning_rate, initial_point):
    x_coords=[initial_point]
    y_coords=[f(initial_point)]
    i=0
    while abs(deriv(f, x_coords[i]))>0.001 : #loop keeps going and adding more points until the derivative is almost 0
        i+=1
        x_coords.append(x_coords[i-1]-learning_rate*deriv(f, x_coords[i-1]))
        y_coords.append(f(x_coords[i-1]-learning_rate*deriv(f, x_coords[i-1])))
    #plotting the function
    plot_range=np.linspace(min(x_coords) - 1, max(x_coords) + 1,10000) #set x range of values to show on graph
    function_range=[f(i) for i in plot_range] #set y range of values to show on graph
    plt.plot(plot_range, function_range) #actual function plot
    plt.plot(x_coords, y_coords) #gradient descent plot
    plt.show()
    return(round(x_coords[i-1],3), round(y_coords[i-1],3)) #returns the final point

print(gradient_descent(f3, 0.03,2))

#what about |x|?
def abx(x): 
    if x>=0:
        return x
    if x<0:
        return -x
#since the function is not differentiable at its minimum (at x = 0), and because the slope never changes, you'll never reach near the minimum
#the descent DTDS will only move back and forth indefinitely
